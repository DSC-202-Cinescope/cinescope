{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d71695-00db-4811-8f6d-88a998b4ffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already imported movie count: 788417\n"
     ]
    }
   ],
   "source": [
    "#### FIX Movie data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Configuration\n",
    "BOLT_URL = \"bolt://neo4j:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASS = \"\"\n",
    "CSV_FILE = \"~/work/cinescope/data/csv-files/movies-master.csv\" \n",
    "CHUNK_SIZE = 1000000  # Adjust as needed\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(BOLT_URL, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "\n",
    "def get_existing_movie_ids():\n",
    "    \"\"\"Retrieve the set of movie IDs already present in Neo4j.\"\"\"\n",
    "    existing_ids = set()\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (m:Movie) RETURN m.id AS id\")\n",
    "        for record in result:\n",
    "            existing_ids.add(record[\"id\"])\n",
    "    return existing_ids\n",
    "\n",
    "def import_missing_movies():\n",
    "    \"\"\"Read the CSV in chunks and import missing Movie nodes into Neo4j.\"\"\"\n",
    "    existing_ids = get_existing_movie_ids()\n",
    "    print(\"Already imported movie count:\", len(existing_ids))\n",
    "    \n",
    "    total_imported = 0\n",
    "    with pd.read_csv(CSV_FILE, chunksize=CHUNK_SIZE, encoding=\"utf-8\") as reader:\n",
    "        for chunk in reader:\n",
    "            # Ensure the 'id' column is integer type\n",
    "            chunk[\"id\"] = chunk[\"id\"].astype(int)\n",
    "            # Filter rows that are not already imported\n",
    "            missing_chunk = chunk[~chunk[\"id\"].isin(existing_ids)]\n",
    "            if missing_chunk.empty:\n",
    "                continue\n",
    "            \n",
    "            # For each missing movie, keep the id and title (adjust columns as needed)\n",
    "            records = missing_chunk[[\"id\", \"title\"]].to_dict(\"records\")\n",
    "            with driver.session() as session:\n",
    "                # Use a write transaction for batch insertion\n",
    "                session.execute_write(batch_import_movies, records)\n",
    "            imported_count = len(records)\n",
    "            total_imported += imported_count\n",
    "            print(f\"Imported {imported_count} movies in this chunk; total imported: {total_imported}\")\n",
    "            # Update existing_ids so subsequent chunks skip these movies\n",
    "            existing_ids.update(missing_chunk[\"id\"].tolist())\n",
    "    print(\"Completed importing missing movies.\")\n",
    "\n",
    "def batch_import_movies(tx, records):\n",
    "    \"\"\"\n",
    "    Batch MERGE missing movies into Neo4j.\n",
    "    This query uses UNWIND for efficiency.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS row\n",
    "    MERGE (m:Movie {id: row.id})\n",
    "    ON CREATE SET m.title = row.title\n",
    "    \"\"\"\n",
    "    tx.run(query, records=records)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_missing_movies()\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba463927-bba4-437e-a29a-e417eba9bb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
